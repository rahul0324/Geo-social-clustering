{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# import necessary modules\nimport pandas as pd, numpy as np, matplotlib.pyplot as plt, time\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# %% [code]\nkms_per_radian = 6371.0088","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf1 = pd.read_csv('../input/geosocial-clustering-of-places-from-check-in-data/Gowalla_totalCheckins.txt', sep='\\t', header=None,nrows = 35000)\ndf1[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns = ['userid','timestamp','latitude','longitude','spotid']\ndf1[0:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pltdata = pd.read_csv('../input/geosocial-clustering-of-places-from-check-in-data/Gowalla_totalCheckins.txt', sep='\\t', header=None,nrows = 35000)\npltdata.columns = ['userid','timestamp','latitude','longitude','spotid']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pltdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BBox = ((pltdata.longitude.min(),pltdata.longitude.max(),pltdata.latitude.min(), pltdata.latitude.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\n## from scipy.spatial.distance import pdist, squareform\nfrom haversine import haversine, Unit\n#distance_matrix = squareform(pdist(df, (lambda u,v: haversine(u,v))))\nfrom sklearn.cluster import DBSCAN\nimport sys\ndata = df1[[\"latitude\", \"longitude\"]]\ndata = data.values.astype(\"float32\", copy = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dbsc = DBSCAN(eps = 25, min_samples = 5).fit(data)\ncore_samples_mask = np.zeros_like(dbsc.labels_, dtype=bool)\ncore_samples_mask[dbsc.core_sample_indices_] = True\nlabels = dbsc.labels_\n\n#data['c_labels'] = labels\n\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Black removed and is used for noise instead.\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = data[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = data[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\n#latitude and longitude\n#to convert numpy.ndarray to dataframe\ndata2 = pd.DataFrame(np.array(data),columns=['a', 'b'])\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\n#cluster labels\ndata3 = pd.DataFrame(np.array(labels),columns=['c'])\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\n#now trying to combine df1 with cluster labels\nfinal1 = pd.concat([df1, data3], axis=1)\ntest1 = final1\ntest1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\n#test1['userid']\n\n# %% [code]\ntest1['countno'] = 1\ncolumns_to = ['countno']\ntest2 = test1.groupby(['userid','c'])[columns_to].count().reset_index()\ntest2\ndf3 = test2.pivot_table('countno',['userid'],'c')\ndf3\ndf4 = df3.fillna(0)\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndbscan = Model(eps=25, min_samples=3)\ndbscan.fit(df4)\n\ncluster_labels1 = dbscan.labels_\nunique_labels = set(cluster_labels1)\n\n# get the number of clusters\nnum_clusters = len(set(cluster_labels1))\n#x =df4\nprint('Number of clusters: {}'.format(num_clusters))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# %% [code]\n#cluster_labels1\n\n# %% [code]\ndf4['u_labels'] = cluster_labels1\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf5 = df4.groupby(['u_labels']).sum().reset_index()\ndf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndbscan = DBSCAN(eps=300, min_samples=2)\ndbscan.fit(df5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_labels = DBSCAN(df4,eps=30,MinPts=2) \n#type(my_labels)\n\ncluster_labels1 = dbscan.labels_\nunique_labels = set(cluster_labels1)\n\n# get the number of clusters\nnum_clusters = len(set(cluster_labels1))\nx =df4\nprint('Number of clusters: {}'.format(num_clusters))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ncluster_labels1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\ndbscan = DBSCAN(eps=30, min_samples=2)\ndbscan.fit(df4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_labels = DBSCAN(df4,eps=30,MinPts=2) \n#type(my_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_labels1 = dbscan.labels_\nunique_labels = set(cluster_labels1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the number of clusters\nnum_clusters = len(set(cluster_labels1))\nx =df4\nprint('Number of clusters: {}'.format(num_clusters))\ndf4['labels1'] = cluster_labels1\n#pd.DataFrame(my_labels)\ndf4\n# Separating out the target\ny = df4.loc[:,['labels1']].values# Standardizing the features\nx = StandardScaler().fit_transform(x)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\nfinalDf = pd.concat([principalDf, df4[['labels1']]], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = unique_labels\n\ncolors = ['r', 'g', 'b']\nfor target in targets:\n    indicesToKeep = finalDf['labels1'] == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n               , finalDf.loc[indicesToKeep, 'principal component 2']\n               \n               , s = 50)\nax.legend(targets)\nax.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ncolors =[]\nunique_labels\ncluster_labels1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ncolumns_to_show = []\ndf5 = df4.groupby(['labels1']).sum().reset_index()\ndf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndbscan = DBSCAN(eps=30, min_samples=1)\ndbscan.fit(df5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_labels = DBSCAN(df4,eps=30,MinPts=2) \n#type(my_labels)\n\ncluster_labels1 = dbscan.labels_\nunique_labels = set(cluster_labels1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the number of clusters\nnum_clusters = len(set(cluster_labels1))\nq =df5\nprint('Number of clusters: {}'.format(num_clusters))\ndf5['labels2']  = cluster_labels1\ndf5\n#pd.DataFrame(my_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating out the target\n\"\"\"\np = df.loc[:,['labels2']].values# Standardizing the features\nq = StandardScaler().fit_transform(q)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(q)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component p1', 'principal component  q2'])\nfinalDf2 = pd.concat([principalDf, df5[['labels2']]], axis = 1)\nfinalDf2\n\n\n\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component p1', fontsize = 15)\nax.set_ylabel('Principal Component q2', fontsize = 15)\nax.set_title('3 component PCA', fontsize = 20)\ntargets = unique_labels\n\ncolors = ['r', 'g', 'b']\nfor target in targets:\n    indicesToKeep = finalDf2['labels2'] == target\n    ax.scatter(finalDf2.loc[indicesToKeep, 'principal component p1']\n               , finalDf2.loc[indicesToKeep, 'principal component q2']\n               \n               , s = 50)\nax.legend(targets)\nax.grid()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %% [code]\ndf5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}